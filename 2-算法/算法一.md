why:机器学习的核心

what:
监督：有标签值
无监督：有标签值，标签值需要被求出

线性回归：回归，无穷时趋向于一个值
分类：


熵	  越大，纯度越低
Gini系数   越大，纯度越低
在决策树的优化时，概率*纯度，越低的，越先决策

信息增溢=原始熵值-此属性下的信息熵

目的：信息增溢越大，使信息熵值下降越迅速，即最优；




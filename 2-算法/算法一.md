why:机器学习的核心

what:
监督：有标签值
无监督：有标签值，标签值需要被求出

线性回归：回归，无穷时趋向于一个值
分类：

## 决策树
<font color='red'>**熵**</font>	  越大，纯度越低
<font color='red'>**Gini系数**</font>   越大，纯度越低
在决策树的优化时，概率*纯度，越低的，越先决策

<font color='red'>**信息增溢**</font>=原始熵值-此属性下的信息熵，信息增溢值越大，越先决策
目的：信息增溢越大，使信息熵值下降越迅速，即最优先决策属性；

<font color='red'>**信息增溢率=信息增溢/熵

目标函数

<font color='red'>**评价函数：叶子节点的熵值越小越好，叶子节点个数=权重

连续型的属性，可离散化处理

<font color='red'>**剪枝
预剪枝
后剪枝


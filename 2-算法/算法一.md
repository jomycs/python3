why:机器学习的核心

what:
监督：有标签值
无监督：有标签值，标签值需要被求出

线性回归：回归，无穷时趋向于一个值
分类：

## 决策树
熵	  越大，纯度越低
Gini系数   越大，纯度越低
在决策树的优化时，概率*纯度，越低的，越先决策

信息增溢=原始熵值-此属性下的信息熵，信息增溢值越大，越先决策
目的：信息增溢越大，使信息熵值下降越迅速，即最优先决策属性；

信息增溢率=信息增溢/熵

目标函数

评价函数：叶子节点的熵值越小越好，叶子节点个数=权重

连续型的属性，可离散化处理

剪枝
预剪枝
后剪枝

